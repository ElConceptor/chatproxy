# ChatProxy - Proxy pour Qualtrics vers ChatGPT

Proxy serveur permettant Ã  un formulaire Qualtrics de communiquer avec l'API ChatGPT en gÃ©rant les problÃ¨mes CORS.

## ğŸš€ Installation

1. Installer les dÃ©pendances :
```bash
npm install
```

2. Copier le fichier `.env.example` vers `.env` :
```bash
cp .env.example .env
```

3. Configurer votre clÃ© API OpenAI dans le fichier `.env` :
```
OPENAI_API_KEY=sk-votre-cle-api-ici
```

## âš™ï¸ Configuration

Modifiez le fichier `.env` pour configurer :

- `PORT` : Port d'Ã©coute du serveur (par dÃ©faut: 3000)
- `OPENAI_API_KEY` : Votre clÃ© API OpenAI (obligatoire)
- `OPENAI_MODEL` : ModÃ¨le Ã  utiliser (par dÃ©faut: gpt-3.5-turbo)
- `OPENAI_TEMPERATURE` : TempÃ©rature de gÃ©nÃ©ration (0.0-2.0)
- `OPENAI_MAX_TOKENS` : Nombre maximum de tokens
- `ALLOWED_ORIGIN` : Origine autorisÃ©e pour CORS (optionnel)

## ğŸƒ DÃ©marrage

```bash
# Mode production
npm start

# Mode dÃ©veloppement (avec rechargement automatique)
npm run dev
```

Le serveur sera accessible sur `http://localhost:3000`

## ğŸ“¡ API Endpoints

### POST /api/chat

Endpoint principal pour envoyer un message Ã  ChatGPT.

**RequÃªte :**
```json
{
  "message": "Bonjour, comment allez-vous ?",
  "systemPrompt": "Vous Ãªtes un assistant utile et professionnel.",
  "conversationHistory": [
    {
      "role": "user",
      "content": "Message prÃ©cÃ©dent"
    },
    {
      "role": "assistant",
      "content": "RÃ©ponse prÃ©cÃ©dente"
    }
  ]
}
```

**RÃ©ponse :**
```json
{
  "success": true,
  "response": "Je vais bien, merci ! Comment puis-je vous aider ?",
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 15,
    "total_tokens": 25
  },
  "model": "gpt-3.5-turbo"
}
```

### GET /api/chat

VÃ©rifie la disponibilitÃ© du service.

### GET /health

VÃ©rifie l'Ã©tat du serveur.

## ğŸ”§ Utilisation avec Qualtrics

Dans votre formulaire Qualtrics, utilisez JavaScript pour appeler l'API :

```javascript
Qualtrics.SurveyEngine.addOnload(function() {
    // Votre code ici
    
    // Exemple d'appel Ã  l'API
    fetch('http://localhost:3000/api/chat', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            message: 'Votre message ici',
            systemPrompt: 'Vous Ãªtes un assistant pour un formulaire Qualtrics'
        })
    })
    .then(response => response.json())
    .then(data => {
        console.log('RÃ©ponse:', data.response);
        // Traiter la rÃ©ponse ici
    })
    .catch(error => {
        console.error('Erreur:', error);
    });
});
```

**Important :** En production, remplacez `http://localhost:3000` par l'URL de votre serveur proxy dÃ©ployÃ©.

## ğŸ”’ SÃ©curitÃ© CORS

Le serveur est configurÃ© pour gÃ©rer les requÃªtes CORS depuis Qualtrics. En dÃ©veloppement, toutes les origines sont autorisÃ©es. En production, configurez `ALLOWED_ORIGIN` dans le fichier `.env` pour restreindre l'accÃ¨s.

## ğŸ“ Notes

- Assurez-vous que votre clÃ© API OpenAI est valide et a des crÃ©dits disponibles
- Le timeout par dÃ©faut est de 30 secondes
- Les erreurs sont loggÃ©es dans la console du serveur

## ğŸ› DÃ©pannage

**Erreur CORS :**
- VÃ©rifiez que l'origine de votre requÃªte Qualtrics est autorisÃ©e
- En dÃ©veloppement, toutes les origines sont autorisÃ©es par dÃ©faut

**Erreur API OpenAI :**
- VÃ©rifiez que votre clÃ© API est correcte dans `.env`
- VÃ©rifiez que vous avez des crÃ©dits disponibles sur votre compte OpenAI

**Port dÃ©jÃ  utilisÃ© :**
- Changez le port dans le fichier `.env` ou arrÃªtez le processus utilisant le port 3000

